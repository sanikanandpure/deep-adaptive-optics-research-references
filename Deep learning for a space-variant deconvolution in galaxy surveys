## citation
F. Sureal _et al._, “Deep learning for a space-variant deconvolution in galaxy surveys”, 2019

## summary
The study uses simulations of realistic galaxy images derived from HST observations, with realistically sampled sparse-variant PSFs and noise, processed with the GalSim simulation code.

## notes
- deconvolution of images require consideration to space-variant point spread function
- deep learning 
- U-net neural networks where a U-shape is created using down and up-sampling (Simply put, it analyzes the image by small pieces -
zooming into tiny details / pixels (down sampling) and then pieces the details together (upsampling).
- 1st approach is a post-processing of a mere Tikhonov deconvolution with closed-form solution
- 2nd approach is an iterative deconvolution framework based on the alternating direction method of multipliers (ADMM).
- these two techniques outperform standard techniques
-- Tikhonov approach yields highly accurate resutls except for ellipticity errors at high signal-to-noise ratio, where the ADMM approach performs slightly better
- Tikhonov is more efficient.

### key points
- PSF (point spread function) ( The PSF field is usually estimated beforehand through parametric models and simulations as in Krist _et al._ (2011) or is directly estimated from
the (noisy) observations of stars in the field of view )
- 
- More than 1000 images were processed
- The proposed deep-learning approaches outperform standard techniques, with the Tikhonet approach achieving an improvement of about 14% in terms of the median pixel error and an improvement of about 13% 
for the median shape measurement errors compared to sparse recovery. We evaluated these approaches compared to the deconvolution techniques in Farrens et al (2017) in simulations of realistic galaxy images 
derived from HST observations, with realistically sampled sparse-variant PSFs and noise, processed with the GalSim simulation code. The situation is more balanced for the ADMMnet, where smaller pixel errors 
can be achieved at low signal-to-noise ratio (S/N) with the classical architecture, but the XDense U-net provides the best results for pixel errors at high S/N and ellipticity errors at high and low S/N
The two methods visually outperform the sparse recovery and low-rank techniques, which display artifacts at the low S/N we probed. This is confirmed in all S/N ranges and for a realistic distribution of S/N. 
In the latter, an improvement of about 14% is achieved in terms of the median pixel error and an improvement of about 13% for the median shape measurement errors for the Tikhonet approach compared to sparse recovery
At higher S/N, the ADMMnet approach leads to slightly smaller ellipticity errors. 
- 

###  method and implementation
- The first method uses a deep neural network
(DNN) to post-process a Tikhonov deconvolution, and the second includes a DNN that is trained to denoise in an iterative
algorithm derived from convex optimization

### deep learning approach
- 

### sample approached logic for the DNN training using the Tikhonov approach
![image]()

### conclusion
- 2 new space-variant deconvolution strategies for galaxy images based on deep neural networks 
- the Tikhonet approach is a post-processing approach of a simple Tikhonov deconvolution with a DNN, 
- the ADMMnet approach is based on regularization by a DNN denoiser inside an iterative ADMM PnP algorithm for deconvolution.

### useful resources we can use: (as used by this article)
https://github.com/pmelchior/shapelens 
https://github.com/sfarrens/sf_deconvolve 
https://github.com/GalSim-developers/GalSim  --- simulation code and potential database
